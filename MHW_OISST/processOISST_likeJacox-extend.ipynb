{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935d9370-0f72-4170-b974-18d63ec481c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9e14dd-5886-489b-8e3c-2e5a1bf9db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "years=[1991,2023]\n",
    "clim_years=[1991,2020]\n",
    "basepath='/space/hall5/sitestore/eccc/crd/ccrn/users/reo000/work/MHW/OISST/'\n",
    "fname=f'oisst-avhrr-v02r01.regridded1x1.monthly.{years[0]}_{years[-1]}.nc'\n",
    "f0=os.path.join(basepath,fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788fc193-b2d5-4fef-8fc0-94b5da0a3765",
   "metadata": {},
   "source": [
    "1. Calculate climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a6e3ed-4184-483b-922c-1e5d039e3505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open sst data\n",
    "fin=xr.open_dataset(f0)\n",
    "\n",
    "# Find year and month (time is in months since 1960-1-1)\n",
    "time=fin.S.values\n",
    "yy=np.array([int(el/12)+1960 for el in time])\n",
    "mm=np.array([int(el%12)+1 for el in time])\n",
    "cyind = (yy>=clim_years[0]) & (yy<=clim_years[-1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "affb662e-58c2-43a6-b91b-1b52c2896d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sst_clim=np.empty((12,len(fin.lat.values),len(fin.lon.values)))\n",
    "# Calculate climatology\n",
    "for im in range(1,13):\n",
    "    ind = (mm==im) & (yy>=clim_years[0]) & (yy<=clim_years[1])\n",
    "    sstsel=fin.sst[ind,:,:].data\n",
    "    sst_clim[im-1,:,:]=sstsel.mean(axis=0)\n",
    "\n",
    "# Save to file\n",
    "f_clim=basepath+f'sst_climatology_oisst-avhrr-v02r01.regridded1x1.monthly.{clim_years[0]}_{clim_years[-1]}.nc'\n",
    "xout=xr.Dataset(data_vars={'lon':(['X',],fin.lon.values),\n",
    "                           'lat':(['Y',],fin.lat.values),\n",
    "                        'sst_clim':(['Mon','Y','X'],sst_clim)},\n",
    "            coords=dict(X=fin.X,Y=fin.Y,Mon=(\"Mon\",np.arange(1,13))),)\n",
    "xout.to_netcdf(f_clim,mode='w')\n",
    "fin.close()\n",
    "print('Done\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e49ee9-ad1c-4ee8-bea1-dedb612a4dc8",
   "metadata": {},
   "source": [
    "2. Calculate anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "347fdade-74a3-4b64-8465-f5da6961089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load climatology\n",
    "fclim = xr.open_dataset(f_clim,decode_times=False)\n",
    "sst_clim = fclim.sst_clim.values\n",
    "\n",
    "# Load obs\n",
    "fin = xr.open_dataset(f0,decode_times=False)\n",
    "sst=fin.sst.values\n",
    "time=fin.time2.values\n",
    "lon=fin.lon.values\n",
    "lat=fin.lat.values\n",
    "\n",
    "# get years and months; full time period\n",
    "yy=np.array([int(el/12)+1960 for el in time])\n",
    "mm=np.array([int(el%12)+1 for el in time])\n",
    "\n",
    "# Loop through time and compute anomalies\n",
    "nt = len(yy)\n",
    "sst_an=np.empty(np.shape(sst))\n",
    "for it in range(0,nt):\n",
    "    sst_an[it,...] = sst[it,...] - sst_clim[mm[it]-1,...]\n",
    "\n",
    "# Save to file\n",
    "f_anom = basepath+f'sst_anomaly_oisst-avhrr-v02r01.regridded1x1.monthly.{years[0]}_{years[-1]}.nc'\n",
    "year = yy;\n",
    "month = mm;\n",
    "xout=xr.Dataset(data_vars={'lon':(['X',],lon),\n",
    "                        'lat':(['Y',],lat),\n",
    "                        'time':(['S'],time),\n",
    "                        'year':(['S'],year),\n",
    "                        'month':(['S'],month),\n",
    "                        'sst_an':(['S','Y','X'],sst_an)},\n",
    "            coords=dict(X=fin.X,Y=fin.Y,S=(\"S\",time)),)\n",
    "xout.to_netcdf(f_anom,mode='w')\n",
    "fin.close()\n",
    "fclim.close()\n",
    "del sst;del sst_an;del time;del year;del month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2047c998-1eba-4082-9015-8a98cb077636",
   "metadata": {},
   "source": [
    "3. Detrend anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6e0ad51-2582-40b5-b664-3c5244e2b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _detrend(data,cind):\n",
    "    # remove trend along first dimension assuming evenly spaced data along that dimension\n",
    "    # reshape to 2-d array to get fit, then transform fit back to original shape\n",
    "    # return data with trend subtracted\n",
    "    # detrend based on clim time period as indicated by cind index\n",
    "    data=np.asarray(data)\n",
    "    dshape = data.shape\n",
    "    N=dshape[0]\n",
    "    X=np.concatenate([np.ones((N,1)), np.expand_dims(np.arange(0,N),1)],1)\n",
    "    M=np.prod(dshape,axis=0) // N # // is floor division\n",
    "    newdata = np.reshape(data,(N, M)) \n",
    "    newdata = newdata.copy() # make sure a copy has been created\n",
    "    # check there aren't extraneous nan's (besides fully masked land cells)\n",
    "    if set(np.unique(np.sum(np.sum(np.isnan(data),axis=1),axis=0))).issubset(set([0,np.prod(data.shape[:2])])):\n",
    "        b, res, p, svs = np.linalg.lstsq(X[cind,:],newdata[cind,:],rcond=None)\n",
    "    else: # extra nan's present; trigger annoying slow loop\n",
    "        print('entering NaN loop')\n",
    "        b=-9*np.ones((2,M))\n",
    "        for ix in range(0,M):\n",
    "            yy=newdata[:,ix]\n",
    "            ind=np.logical_and(~np.isnan(yy), cind)\n",
    "            xx=X[ind,:]\n",
    "            yy=yy[ind].reshape((np.sum(ind),1))\n",
    "            bb, res, p, svs = np.linalg.lstsq(xx,yy,rcond=None)\n",
    "            b[:,ix]=bb[:,0]\n",
    "        assert np.sum(b==-9)==0\n",
    "    bshp = tuple([2]+list(dshape)[1:])\n",
    "    b=np.reshape(b,bshp)\n",
    "    trnd=np.arange(0,N).reshape((N,)+tuple(np.ones(len(dshape)-1,dtype=int))) * b[1,...].reshape((1,)+np.shape(b[1,...]))+\\\n",
    "                b[0,...].reshape((1,)+np.shape(b[0,:,:]))\n",
    "    return data-trnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87c56755-8aa8-4bb2-8c73-961652e18b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering NaN loop\n"
     ]
    }
   ],
   "source": [
    "# Load anomalies\n",
    "fin=xr.open_dataset(f_anom,decode_times=False)\n",
    "\n",
    "# Detrend\n",
    "sst_an_dt = _detrend(fin.sst_an.data,cyind)\n",
    "\n",
    "# Save to file\n",
    "f_anom_dt = basepath+f'sst_anomaly_detrended_oisst-avhrr-v02r01.regridded1x1.monthly.{years[0]}_{years[-1]}_clim{clim_years[0]}_{clim_years[-1]}.nc'\n",
    "\n",
    "xout=xr.Dataset(data_vars={'lon':(['X',],fin.lon.values),\n",
    "                        'lat':(['Y',],fin.lat.values),\n",
    "                        'time':(['S'],fin.time.values),\n",
    "                        'year':(['S'],fin.year.values),\n",
    "                        'month':(['S'],fin.month.values),\n",
    "                        'sst_an_dt':(['S','Y','X'],sst_an_dt)},\n",
    "            coords=dict(X=fin.X,Y=fin.Y,S=fin.S),)\n",
    "xout.to_netcdf(f_anom_dt,mode='w')\n",
    "fin.close()\n",
    "del sst_an_dt;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa68d5a-af7a-4acf-87e7-af854164e536",
   "metadata": {},
   "source": [
    "4. Calculate MHWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8525dd7-a3fd-4b0c-a77d-c3a85780e50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for is_detrend in (True,False):\n",
    "    # Load anomalies        \n",
    "    if is_detrend:\n",
    "        fin=xr.open_dataset(f_anom_dt)\n",
    "        sst_an=fin.sst_an_dt.values\n",
    "    else:\n",
    "        fin=xr.open_dataset(f_anom)\n",
    "        sst_an=fin.sst_an.values\n",
    "    month=fin.month.values\n",
    "    year=fin.year.values\n",
    "    \n",
    "    # Loop through month and compute sst anomaly thresholds for MHWs\n",
    "    # Thresholds are computed with a 3-month moving window\n",
    "    sst_an_thr=np.zeros((12,len(fin.Y),len(fin.X)))\n",
    "    for ii in range(1,13): # month\n",
    "        if ii==1:\n",
    "            tind = ((month==12) | (month<=2)) & (year>=clim_years[0]) & (year<=clim_years[1])\n",
    "        elif ii==12:\n",
    "            tind = ((month==1) | (month>=11)) & (year>=clim_years[0]) & (year<=clim_years[1])\n",
    "        else:\n",
    "            tind = (month>=ii-1) & (month<=ii+1) & (year>=clim_years[0]) & (year<=clim_years[1])\n",
    "        tmp = sst_an[tind,...]\n",
    "        sst_an_thr[ii-1,...] = np.quantile(tmp,0.9,axis=0)\n",
    "    \n",
    "    # Find points that exceed thresholds\n",
    "    is_mhw=np.zeros(np.shape(sst_an))\n",
    "    for ii in range(0,np.shape(sst_an)[0]):\n",
    "        mm=month[ii]\n",
    "        is_mhw[ii,...]=np.where(sst_an[ii,...]>np.expand_dims(sst_an_thr[mm-1,...],0),1,0)\n",
    "    \n",
    "    # Save to file\n",
    "    if is_detrend:\n",
    "        f_mhw = basepath+f'mhw_detrended_oisst-avhrr-v02r01.regridded1x1.monthly.{years[0]}_{years[-1]}_clim{clim_years[0]}_{clim_years[-1]}.nc'\n",
    "    else:\n",
    "        f_mhw = basepath+f'mhw_oisst-avhrr-v02r01.regridded1x1.monthly.{years[0]}_{years[-1]}_clim{clim_years[0]}_{clim_years[-1]}.nc'\n",
    "    xout=xr.Dataset(data_vars={'lon':(['X',],fin.lon.values),\n",
    "                        'lat':(['Y',],fin.lat.values),\n",
    "                        'time':(['S'],fin.time.values),\n",
    "                        'year':(['S'],fin.year.values),\n",
    "                        'month':(['S'],fin.month.values),\n",
    "                        'sst_an_thr':(['Mon','Y','X'],sst_an_thr),\n",
    "                        'is_mhw':(['S','Y','X'],is_mhw),},\n",
    "            coords=dict(X=fin.X,Y=fin.Y,S=fin.S,Mon=(\"Mon\",np.arange(1,13))),)\n",
    "    xout.to_netcdf(f_mhw,mode='w')\n",
    "    fin.close()\n",
    "    del sst_an_thr; del is_mhw; del sst_an;\n",
    "print('\\nDone\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7a0ee-4e58-482c-9442-7c674b79399a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713888a7-8844-4b2a-bd90-79a641b1a41e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mpy12MHW)",
   "language": "python",
   "name": "mpy12mhw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
